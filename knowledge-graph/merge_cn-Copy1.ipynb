{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, RDF, URIRef, RDFS\n",
    "from rdflib.namespace import OWL, SKOS\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespace(graph, namespace, prefix):\n",
    "    \"\"\"\n",
    "    Binds a namespace to a given graph.\n",
    "    Args:\n",
    "        - graph: graph object\n",
    "        - namespace: uri of the namespace to be bound to the graph\n",
    "        - prefix: the prefix of the given namespace\n",
    "    Output: namespace instance bound to a specified graph\n",
    "    \"\"\"\n",
    "    ns = Namespace(namespace)\n",
    "    graph.namespace_manager.bind(prefix, namespace)\n",
    "\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N243a57b96db247f0a39e928f916f2717 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load graphs to be merged\n",
    "base_graph_file = \"./graphs/aff_bft_open_graph.ttl\"\n",
    "cn_graph_file = \"../data/ConceptNet/parse/cn_graph.ttl\"\n",
    "base_g = Graph()\n",
    "cn_g = Graph()\n",
    "base_g.parse(base_graph_file, format= 'turtle')\n",
    "cn_g.parse(cn_graph_file, format= 'turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine graphs\n",
    "merged_g = Graph()\n",
    "merged_g = base_g + cn_g\n",
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CN Relations with aff ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnr_ns = create_namespace(merged_g, \"http://api.conceptnet.io/r/\", 'cnr')\n",
    "cnc_ns = create_namespace(merged_g, \"http://api.conceptnet.io/c/\", 'cnc')\n",
    "aff_ns = create_namespace(merged_g, \"http://test.org/affordance.owl#\", 'aff')\n",
    "kchn_ns = create_namespace(merged_g, \"http://test.org/kitchen.owl#\", 'kchn')\n",
    "skos_ns = create_namespace(merged_g, \"http://www.w3.org/2004/02/skos/core#\", 'skos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:UsedFor_ --> action instances and affordance subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create Actions from cnr:UsedFor using SpaCy\n",
    "aff_df = pd.DataFrame(columns=['usage_o', 'usage_phrase_list', 'aff_class'])\n",
    "\n",
    "# lists to store df values\n",
    "usages = []\n",
    "usage_phrase_list = []\n",
    "\n",
    "# iterate through graph triples with UsedFor relation\n",
    "# Object values are the usages that will be actions and their VERB will be subclasses of affordances\n",
    "for s,p,o in merged_g.triples( (None, cnr_ns.UsedFor, None) ):\n",
    "    usages.append(o[30:])\n",
    "    usage_phrase = ' '.join(o[30:].split('_'))\n",
    "    usage_phrase_list.append(usage_phrase)\n",
    "\n",
    "# fill df\n",
    "aff_df.usage_o = usages\n",
    "aff_df.usage_phrase_list = usage_phrase_list\n",
    "# aff_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aff_subclass(text):\n",
    "    \"\"\"\n",
    "    Determines the affordance action from the object value of the cnr:UsedFor triples. \n",
    "    Args:\n",
    "        text: value in dataframe cell\n",
    "    Returns:\n",
    "        action (str): action value that will be a subclass of Affordance\n",
    "    \"\"\"\n",
    "    verb_exists = False\n",
    "    words = []\n",
    "    pos = []\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for tok in doc:\n",
    "        word = tok.text\n",
    "        pos_ = tok.pos_\n",
    "        tokens.append(tok)\n",
    "        words.append(word)\n",
    "        pos.append(pos_)\n",
    "        \n",
    "    if \"VERB\" in pos:\n",
    "        pos_index = pos.index(\"VERB\")\n",
    "        verb_word = words[pos_index]\n",
    "        verb_exists = True\n",
    "    else:\n",
    "        action = None\n",
    "    \n",
    "    if verb_exists:\n",
    "        if verb_word[-3:] == 'ing':\n",
    "            action = verb_word.capitalize()\n",
    "        else:\n",
    "            action = verb_word.capitalize() +'ing'\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the df\n",
    "aff_df['aff_class'] = aff_df['usage_phrase_list'].apply(get_aff_subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_col(text):\n",
    "    \"\"\"\n",
    "    For the action affordances determined, filter out specific words that resulted with typos.\n",
    "    \"\"\"            \n",
    "    edit_out = ['Storeing', 'Stiring', 'Runing', 'Pareing', 'Serveding', 'Leaveing']\n",
    "    edit_in = ['Storing', 'Stirring', 'Running', 'Paring', 'Serving', 'Leaving']\n",
    "    \n",
    "    if text in edit_out:\n",
    "        index = edit_out.index(text)\n",
    "        new_text = edit_in[index]\n",
    "        return new_text\n",
    "    else:\n",
    "        return text\n",
    "        \n",
    "# apply the function to the df\n",
    "aff_df['aff_class'] = aff_df['aff_class'].apply(filter_col)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the desired triples for the graph\n",
    "\n",
    "# < affordance subclass, rdfs:subClassOf, aff:Affordance >\n",
    "action_affs = aff_df.aff_class.to_list()\n",
    "action_affs_set = set(action_affs)\n",
    "action_affs_set.remove(None)\n",
    "for aff in action_affs_set:\n",
    "    merged_g.add( (aff_ns[URIRef(aff)], RDFS.subClassOf, aff_ns.Affordance) )\n",
    "\n",
    "for index, row in aff_df.iterrows():\n",
    "    # < UsedFor object, a, aff:Action >\n",
    "    merged_g.add( (cnc_ns[row['usage_o']], RDF.type, aff_ns.Action) )\n",
    "    # < UsedFor object, a, Affordance Subclass >\n",
    "    if row['aff_class'] == None:\n",
    "        continue\n",
    "    else:\n",
    "        merged_g.add( (cnc_ns[row['usage_o']], RDF.type, aff_ns[row['aff_class']]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1558"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:ReceivesAction_ --> removing these triples because other relations give similar information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in merged_g.triples( (None, cnr_ns.ReceivesAction, None) ):\n",
    "    merged_g.remove( (cnc_ns[s[27:]], cnr_ns.ReceivesAction, cnc_ns[o[27:]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:MadeOf_ --> only keep triples in which the subject of the triple is an instance of the BFT onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = ['croissant', 'garnish', 'hardboiled_egg', 'scrambled_egg', 'fried_egg', 'orange_juice', 'apple_juice', 'butter', 'salt_shaker', 'pepper_shaker', 'bread_basket', 'egg_cup', 'milk_pitcher', 'fork', 'knife', 'spoon', 'butter_knife', 'glass', 'teacup', 'sauce_dish', 'butter_dish', 'bread_plate', 'teacup_plate', 'dining_table', 'dining_chair', 'cupboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in merged_g.triples( (None, cnr_ns.MadeOf, None) ):\n",
    "    if s[30:] not in instances:\n",
    "        merged_g.remove( (cnc_ns[s[27:]], cnr_ns.MadeOf, cnc_ns[o[27:]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:PartOf_ --> remove triples about glass because they are not very relevant to the kitchen domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in merged_g.triples( (None, cnr_ns.PartOf, None) ):\n",
    "    if \"glass\" in s[30:]:\n",
    "        merged_g.remove( (cnc_ns[s[27:]], cnr_ns.PartOf, cnc_ns[o[27:]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:HasPrequisite_ --> allocate 'A' in cnr:HasPrerequisite to a subclass of aff:Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_classes = set()\n",
    "actions = []\n",
    "for s,p,o in merged_g.triples( (None, cnr_ns.HasPrerequisite, None) ):\n",
    "    action_verb = s[30:].split('_')\n",
    "    action_aff = action_verb[0]\n",
    "    action_aff_uri = URIRef(action_aff.capitalize())\n",
    "#     print(action_aff)\n",
    "    merged_g.add( (cnc_ns[s[27:]], RDF.type, aff_ns.Action) )\n",
    "#     print((cnc_ns[s[27:]], RDF.type, aff_ns.Action))\n",
    "    merged_g.add( (aff_ns[action_aff_uri], RDFS.subClassOf, aff_ns.Affordance) )\n",
    "    merged_g.add( (cnc_ns[s[27:]], RDF.type, aff_ns[action_aff_uri]) )\n",
    "    \n",
    "#     print((cnc_ns[s[27:]], RDF.type, aff_ns[action_aff_uri]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CN Concepts with BFT ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct_s = cn_g.query(\n",
    "# \"\"\"\n",
    "# prefix cn: <http://api.conceptnet.io/> \n",
    "# prefix cnc: <http://api.conceptnet.io/c/> \n",
    "# prefix cnr: <http://api.conceptnet.io/r/> \n",
    "# prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "# prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "# prefix wi: <http://purl.org/ontology/wi/core#> \n",
    "# prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "# prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "# SELECT distinct ?s WHERE { \n",
    "#   ?s a rdfs:Resource. \n",
    "#   ?assertion rdf:subject ?s;\n",
    "#              rdf:predicate ?p.\n",
    "#   FILTER(! (?p = cnr:ExternalURL) )\n",
    "# }\n",
    "# \"\"\")\n",
    "# len(distinct_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_s = cn_g.query(\n",
    "\"\"\"\n",
    "prefix cn: <http://api.conceptnet.io/> \n",
    "prefix cnc: <http://api.conceptnet.io/c/> \n",
    "prefix cnr: <http://api.conceptnet.io/r/> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix wi: <http://purl.org/ontology/wi/core#> \n",
    "prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "SELECT distinct ?s WHERE { \n",
    "  ?s ?p ?o.\n",
    "  FILTER(! (?p = cnr:ExternalURL) )\n",
    "}\n",
    "\"\"\")\n",
    "len(distinct_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_o = cn_g.query(\n",
    "\"\"\"\n",
    "prefix cnr: <http://api.conceptnet.io/r/> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix wi: <http://purl.org/ontology/wi/core#> \n",
    "prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "SELECT distinct ?o WHERE { \n",
    "  ?s ?p ?o.\n",
    "  FILTER(! (?p = cnr:ExternalURL) )\n",
    "}\n",
    "\"\"\")\n",
    "len(distinct_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance to compare strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein\n",
    "# import the enchant module \n",
    "import enchant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# subject case\n",
    "c=0\n",
    "with open('test_s.txt', 'w') as file:\n",
    "    for i in instances:\n",
    "        str1 = i\n",
    "        for r in distinct_s:\n",
    "            str2 = r.s[30:]\n",
    "#             print(str1, str2)\n",
    "            dist = enchant.utils.levenshtein(str1, str2)\n",
    "            ratio = ((len(str1)+len(str2)) - dist) / (len(str1)+len(str2))\n",
    "            if ratio > 0.83:\n",
    "                c +=1\n",
    "                file.write(f'{str(ratio)} -- {i} -- {r.s[30:]}\\n')\n",
    "#                 print(cnc_ns[r.s[32:]])\n",
    "                merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), OWL.sameAs, cnc_ns[r.s[27:]]))\n",
    "#                 print(cnc_ns[r.s[27:]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# object case\n",
    "c1=0\n",
    "with open('test_o.txt', 'w') as file:\n",
    "    for i in instances:\n",
    "        str1 = i\n",
    "        for r in distinct_o:\n",
    "#             print(str1, str2)\n",
    "            str2 = r.o[30:]\n",
    "            dist = enchant.utils.levenshtein(str1, str2)\n",
    "            ratio = ((len(str1)+len(str2)) - dist) / (len(str1)+len(str2))\n",
    "            if ratio > 0.83:\n",
    "                c1 += 1\n",
    "                file.write(f'{str(ratio)} -- {i} -- {r.o[30:]}\\n')\n",
    "                merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), OWL.sameAs, cnc_ns[r.o[27:]]))\n",
    "#                 print(cnc_ns[r.o[27:]])\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# exact match of string matching (comparing how this works against the Levenshtein method)\n",
    "cnt = 0\n",
    "for i in instances:\n",
    "    for r in distinct_s:\n",
    "#         print(i, r.s[30:])\n",
    "        if i == str(r.s[30:]):\n",
    "            cnt +=1\n",
    "    for r in distinct_o:\n",
    "#         print(i, r.o)\n",
    "        if i == str(r.o[30:]):\n",
    "            cnt +=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that more links are created through the Levenshtein algorithm compared to the exact string match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1558"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that 67 triples are added to the graph after linking CN graph to base graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create closeMatch links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links instances following that the instance string is in the response string\n",
    "# eg. if instance is 'croissant' and the repsonse is 'butter_croissant', it would be a match\n",
    "\n",
    "same_as_objects = []\n",
    "for s,p,o in merged_g.triples( (None, OWL.sameAs, None) ):\n",
    "#     print(s,p,o)\n",
    "    same_as_objects.append(o[30:])\n",
    "#     print(o[30:])\n",
    "\n",
    "with open('test_contains.txt', 'w') as file:  # Use file to refer to the file object\n",
    "    for i in instances:\n",
    "        for r in distinct_s:\n",
    "            s_concept = str(r.s[32:])\n",
    "            if i in s_concept:\n",
    "                if s_concept in same_as_objects:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{i} ------- {str(r.s)}\\n')\n",
    "                    merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), skos_ns.closeMatch, cnc_ns[r.s[32:]]) ) \n",
    "        for r in distinct_o:\n",
    "            o_concept = str(r.o[32:])\n",
    "            if i in o_concept:\n",
    "                if o_concept in same_as_objects:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{i} ------- {str(r.o)}\\n')\n",
    "                    merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), skos_ns.closeMatch, cnc_ns[r.o[32:]]) )\n",
    "    \n",
    "# if the triple exists with that subject, then continue because there is an owlsameas triple of the instnace, else make the triple with skos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize and save new merged graph with CN entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_g.serialize('aff_bft_cn_TEST.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1638"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
