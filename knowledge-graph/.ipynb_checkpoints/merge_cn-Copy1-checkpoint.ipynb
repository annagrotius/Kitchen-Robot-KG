{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, RDF, URIRef, RDFS\n",
    "from rdflib.namespace import OWL, SKOS\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespace(graph, namespace, prefix):\n",
    "    \"\"\"\n",
    "    Binds a namespace to a given graph.\n",
    "    Args:\n",
    "        - graph: graph object\n",
    "        - namespace: uri of the namespace to be bound to the graph\n",
    "        - prefix: the prefix of the given namespace\n",
    "    Output: namespace instance bound to a specified graph\n",
    "    \"\"\"\n",
    "    ns = Namespace(namespace)\n",
    "    graph.namespace_manager.bind(prefix, namespace)\n",
    "\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nda52425b31614e7297ac03218358f90c (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load graphs to be merged\n",
    "base_graph_file = \"./graphs/aff_bft_open_graph.ttl\"\n",
    "cn_graph_file = \"../data/ConceptNet/parse/cn_graph.ttl\"\n",
    "base_g = Graph()\n",
    "cn_g = Graph()\n",
    "base_g.parse(base_graph_file, format= 'turtle')\n",
    "cn_g.parse(cn_graph_file, format= 'turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1625"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine graphs\n",
    "merged_g = Graph()\n",
    "merged_g = base_g + cn_g\n",
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CN Relations with aff ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnr_ns = create_namespace(merged_g, \"http://api.conceptnet.io/r/\", 'cnr')\n",
    "cnc_ns = create_namespace(merged_g, \"http://api.conceptnet.io/c/\", 'cnc')\n",
    "aff_ns = create_namespace(merged_g, \"http://test.org/affordance.owl#\", 'aff')\n",
    "kchn_ns = create_namespace(merged_g, \"http://test.org/kitchen.owl#\", 'kchn')\n",
    "skos_ns = create_namespace(merged_g, \"http://www.w3.org/2004/02/skos/core#\", 'skos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:UsedFor_ --> action instances and affordance subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>usage_o</th>\n",
       "      <th>usage_phrase_list</th>\n",
       "      <th>aff_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en/refrigerator</td>\n",
       "      <td>preventing_food_from_going_bad</td>\n",
       "      <td>preventing food from going bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>counting_pills</td>\n",
       "      <td>counting pills</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>alter_length_of_string_or_rope</td>\n",
       "      <td>alter length of string or rope</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>removing_labels</td>\n",
       "      <td>removing labels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>pricking_skin</td>\n",
       "      <td>pricking skin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>digging</td>\n",
       "      <td>digging</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>working_with_wood</td>\n",
       "      <td>working with wood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en/fork</td>\n",
       "      <td>moving_food_to_mouth</td>\n",
       "      <td>moving food to mouth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>en/dining_table</td>\n",
       "      <td>eating_dinner_on</td>\n",
       "      <td>eating dinner on</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>eat_yogurt</td>\n",
       "      <td>eat yogurt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>en/dining_table</td>\n",
       "      <td>family_gatherings</td>\n",
       "      <td>family gatherings</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en/refrigerator</td>\n",
       "      <td>causing_jello_to_jell</td>\n",
       "      <td>causing jello to jell</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>en/apple</td>\n",
       "      <td>making_applesauce</td>\n",
       "      <td>making applesauce</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>cut_string</td>\n",
       "      <td>cut string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>en/dining_table</td>\n",
       "      <td>family_discussions</td>\n",
       "      <td>family discussions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>boning</td>\n",
       "      <td>boning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>en/apple</td>\n",
       "      <td>enjoy_fruit</td>\n",
       "      <td>enjoy fruit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en/refrigerator</td>\n",
       "      <td>storing_foods</td>\n",
       "      <td>storing foods</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>cracking_open</td>\n",
       "      <td>cracking open</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>drinking</td>\n",
       "      <td>drinking</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>mixing_soup</td>\n",
       "      <td>mixing soup</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>en/cupboard</td>\n",
       "      <td>keeping_cups</td>\n",
       "      <td>keeping cups</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>slitting</td>\n",
       "      <td>slitting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>slicing_bread</td>\n",
       "      <td>slicing bread</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>en/fork</td>\n",
       "      <td>eat_meal</td>\n",
       "      <td>eat meal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>breaking_down_into_pieces</td>\n",
       "      <td>breaking down into pieces</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>en/milk</td>\n",
       "      <td>feed_baby</td>\n",
       "      <td>feed baby</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>en/dining_table</td>\n",
       "      <td>playing_cards</td>\n",
       "      <td>playing cards</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>stir_soup</td>\n",
       "      <td>stir soup</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>eat_cereal_with</td>\n",
       "      <td>eat cereal with</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>en/dining_table</td>\n",
       "      <td>having_friends_around_for_dinner</td>\n",
       "      <td>having friends around for dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>liquid_foods</td>\n",
       "      <td>liquid foods</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>en/glass</td>\n",
       "      <td>drinking_liquid_from</td>\n",
       "      <td>drinking liquid from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>en/fork</td>\n",
       "      <td>picking_up_food</td>\n",
       "      <td>picking up food</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>en/refrigerator</td>\n",
       "      <td>keeping_food_cold</td>\n",
       "      <td>keeping food cold</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>en/apple</td>\n",
       "      <td>make_pie</td>\n",
       "      <td>make pie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>en/glass</td>\n",
       "      <td>drinking_out_of</td>\n",
       "      <td>drinking out of</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>en/apple</td>\n",
       "      <td>making_apple_pie</td>\n",
       "      <td>making apple pie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>en/cupboard</td>\n",
       "      <td>store_christmas_decorations</td>\n",
       "      <td>store christmas decorations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>en/apple</td>\n",
       "      <td>bait_trap</td>\n",
       "      <td>bait trap</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>en/dining_table</td>\n",
       "      <td>playing_games_on</td>\n",
       "      <td>playing games on</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>dish_to_run_away_with</td>\n",
       "      <td>dish to run away with</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>cutting</td>\n",
       "      <td>cutting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>cut_meat_with</td>\n",
       "      <td>cut meat with</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>splitting</td>\n",
       "      <td>splitting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>en/killing_people</td>\n",
       "      <td>knife</td>\n",
       "      <td>knife</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>en/setting_cup_on_table</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>en/cupboard</td>\n",
       "      <td>store_bread</td>\n",
       "      <td>store bread</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>en/knife</td>\n",
       "      <td>dividing</td>\n",
       "      <td>dividing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>en/spoon</td>\n",
       "      <td>hang_on_nose</td>\n",
       "      <td>hang on nose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entities                           usage_o  \\\n",
       "0           en/refrigerator    preventing_food_from_going_bad   \n",
       "1                  en/knife                    counting_pills   \n",
       "2                  en/knife    alter_length_of_string_or_rope   \n",
       "3                  en/knife                   removing_labels   \n",
       "4                  en/knife                     pricking_skin   \n",
       "5                  en/knife                           digging   \n",
       "6                  en/knife                 working_with_wood   \n",
       "7                   en/fork              moving_food_to_mouth   \n",
       "8           en/dining_table                  eating_dinner_on   \n",
       "9                  en/spoon                        eat_yogurt   \n",
       "10          en/dining_table                 family_gatherings   \n",
       "11          en/refrigerator             causing_jello_to_jell   \n",
       "12                 en/apple                 making_applesauce   \n",
       "13                 en/knife                        cut_string   \n",
       "14          en/dining_table                family_discussions   \n",
       "15                 en/knife                            boning   \n",
       "16                 en/apple                       enjoy_fruit   \n",
       "17          en/refrigerator                     storing_foods   \n",
       "18                 en/knife                     cracking_open   \n",
       "19                 en/spoon                          drinking   \n",
       "20                 en/spoon                       mixing_soup   \n",
       "21              en/cupboard                      keeping_cups   \n",
       "22                 en/knife                          slitting   \n",
       "23                 en/knife                     slicing_bread   \n",
       "24                  en/fork                          eat_meal   \n",
       "25                 en/knife         breaking_down_into_pieces   \n",
       "26                  en/milk                         feed_baby   \n",
       "27          en/dining_table                     playing_cards   \n",
       "28                 en/spoon                         stir_soup   \n",
       "29                 en/spoon                   eat_cereal_with   \n",
       "30          en/dining_table  having_friends_around_for_dinner   \n",
       "31                 en/spoon                      liquid_foods   \n",
       "32                 en/glass              drinking_liquid_from   \n",
       "33                  en/fork                   picking_up_food   \n",
       "34          en/refrigerator                 keeping_food_cold   \n",
       "35                 en/apple                          make_pie   \n",
       "36                 en/glass                   drinking_out_of   \n",
       "37                 en/apple                  making_apple_pie   \n",
       "38              en/cupboard       store_christmas_decorations   \n",
       "39                 en/apple                         bait_trap   \n",
       "40          en/dining_table                  playing_games_on   \n",
       "41                 en/spoon             dish_to_run_away_with   \n",
       "42                 en/knife                           cutting   \n",
       "43                 en/knife                     cut_meat_with   \n",
       "44                 en/knife                         splitting   \n",
       "45        en/killing_people                             knife   \n",
       "46  en/setting_cup_on_table                            coffee   \n",
       "47              en/cupboard                       store_bread   \n",
       "48                 en/knife                          dividing   \n",
       "49                 en/spoon                      hang_on_nose   \n",
       "\n",
       "                   usage_phrase_list aff_class  \n",
       "0     preventing food from going bad       NaN  \n",
       "1                     counting pills       NaN  \n",
       "2     alter length of string or rope       NaN  \n",
       "3                    removing labels       NaN  \n",
       "4                      pricking skin       NaN  \n",
       "5                            digging       NaN  \n",
       "6                  working with wood       NaN  \n",
       "7               moving food to mouth       NaN  \n",
       "8                   eating dinner on       NaN  \n",
       "9                         eat yogurt       NaN  \n",
       "10                 family gatherings       NaN  \n",
       "11             causing jello to jell       NaN  \n",
       "12                 making applesauce       NaN  \n",
       "13                        cut string       NaN  \n",
       "14                family discussions       NaN  \n",
       "15                            boning       NaN  \n",
       "16                       enjoy fruit       NaN  \n",
       "17                     storing foods       NaN  \n",
       "18                     cracking open       NaN  \n",
       "19                          drinking       NaN  \n",
       "20                       mixing soup       NaN  \n",
       "21                      keeping cups       NaN  \n",
       "22                          slitting       NaN  \n",
       "23                     slicing bread       NaN  \n",
       "24                          eat meal       NaN  \n",
       "25         breaking down into pieces       NaN  \n",
       "26                         feed baby       NaN  \n",
       "27                     playing cards       NaN  \n",
       "28                         stir soup       NaN  \n",
       "29                   eat cereal with       NaN  \n",
       "30  having friends around for dinner       NaN  \n",
       "31                      liquid foods       NaN  \n",
       "32              drinking liquid from       NaN  \n",
       "33                   picking up food       NaN  \n",
       "34                 keeping food cold       NaN  \n",
       "35                          make pie       NaN  \n",
       "36                   drinking out of       NaN  \n",
       "37                  making apple pie       NaN  \n",
       "38       store christmas decorations       NaN  \n",
       "39                         bait trap       NaN  \n",
       "40                  playing games on       NaN  \n",
       "41             dish to run away with       NaN  \n",
       "42                           cutting       NaN  \n",
       "43                     cut meat with       NaN  \n",
       "44                         splitting       NaN  \n",
       "45                             knife       NaN  \n",
       "46                            coffee       NaN  \n",
       "47                       store bread       NaN  \n",
       "48                          dividing       NaN  \n",
       "49                      hang on nose       NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Actions from cnr:UsedFor using SpaCy\n",
    "aff_df = pd.DataFrame(columns=['entities', 'usage_o', 'usage_phrase_list', 'aff_class'])\n",
    "\n",
    "# lists to store df values\n",
    "entities = []\n",
    "usages = []\n",
    "usage_phrase_list = []\n",
    "\n",
    "# iterate through graph triples with UsedFor relation\n",
    "# Object values are the usages that will be actions and their VERB will be subclasses of affordances\n",
    "for s,p,o in merged_g.triples( (None, cnr_ns.UsedFor, None) ):\n",
    "#     print(s,p,o)\n",
    "    usages.append(o[30:])\n",
    "    entities.append(s[27:])\n",
    "#     print(s[27:])\n",
    "    usage_phrase = ' '.join(o[30:].split('_'))\n",
    "    usage_phrase_list.append(usage_phrase)\n",
    "\n",
    "# fill df\n",
    "aff_df.entities = entities\n",
    "aff_df.usage_o = usages\n",
    "aff_df.usage_phrase_list = usage_phrase_list\n",
    "aff_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aff_subclass(text):\n",
    "    \"\"\"\n",
    "    Determines the affordance action from the object value of the cnr:UsedFor triples. \n",
    "    Args:\n",
    "        text: value in dataframe cell\n",
    "    Returns:\n",
    "        action (str): action value that will be a subclass of Affordance\n",
    "    \"\"\"\n",
    "    verb_exists = False\n",
    "    words = []\n",
    "    pos = []\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for tok in doc:\n",
    "        word = tok.text\n",
    "        pos_ = tok.pos_\n",
    "        tokens.append(tok)\n",
    "        words.append(word)\n",
    "        pos.append(pos_)\n",
    "        \n",
    "    if \"VERB\" in pos:\n",
    "        pos_index = pos.index(\"VERB\")\n",
    "        verb_word = words[pos_index]\n",
    "        verb_exists = True\n",
    "    else:\n",
    "        action = None\n",
    "    \n",
    "    if verb_exists:\n",
    "        if verb_word[-3:] == 'ing':\n",
    "            action = verb_word.capitalize()\n",
    "        else:\n",
    "            action = verb_word.capitalize() +'ing'\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the df\n",
    "aff_df['aff_class'] = aff_df['usage_phrase_list'].apply(get_aff_subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arranging',\n",
       " 'Attaching',\n",
       " 'Attacking',\n",
       " 'Breaking',\n",
       " 'Carving',\n",
       " 'Causing',\n",
       " 'Chilling',\n",
       " 'Chopping',\n",
       " 'Complementing',\n",
       " 'Completing',\n",
       " 'Conserving',\n",
       " 'Consuming',\n",
       " 'Cooling',\n",
       " 'Counting',\n",
       " 'Cracking',\n",
       " 'Cuting',\n",
       " 'Cutting',\n",
       " 'Decorating',\n",
       " 'Digging',\n",
       " 'Dishing',\n",
       " 'Dividing',\n",
       " 'Doing',\n",
       " 'Drinking',\n",
       " 'Eating',\n",
       " 'Engraving',\n",
       " 'Enjoying',\n",
       " 'Entertaining',\n",
       " 'Extending',\n",
       " 'Fighting',\n",
       " 'Flinging',\n",
       " 'Freezing',\n",
       " 'Gashing',\n",
       " 'Getting',\n",
       " 'Giving',\n",
       " 'Gouging',\n",
       " 'Hanging',\n",
       " 'Having',\n",
       " 'Holding',\n",
       " 'Illustrating',\n",
       " 'Keeping',\n",
       " 'Killing',\n",
       " 'Laying',\n",
       " 'Leaveing',\n",
       " 'Leaving',\n",
       " 'Letting',\n",
       " 'Lifting',\n",
       " 'Living',\n",
       " 'Makeing',\n",
       " 'Making',\n",
       " 'Measuring',\n",
       " 'Mixing',\n",
       " 'Moving',\n",
       " None,\n",
       " 'Pareing',\n",
       " 'Paring',\n",
       " 'Peeling',\n",
       " 'Picking',\n",
       " 'Piercing',\n",
       " 'Placing',\n",
       " 'Playing',\n",
       " 'Posting',\n",
       " 'Preserving',\n",
       " 'Preventing',\n",
       " 'Pricking',\n",
       " 'Providing',\n",
       " 'Prying',\n",
       " 'Putting',\n",
       " 'Refrigerating',\n",
       " 'Removing',\n",
       " 'Representing',\n",
       " 'Ripping',\n",
       " 'Saving',\n",
       " 'Scooping',\n",
       " 'Scoring',\n",
       " 'Scratching',\n",
       " 'Seeing',\n",
       " 'Separating',\n",
       " 'Serving',\n",
       " 'Severing',\n",
       " 'Sitting',\n",
       " 'Skinning',\n",
       " 'Spearing',\n",
       " 'Spreading',\n",
       " 'Stacking',\n",
       " 'Staying',\n",
       " 'Stiring',\n",
       " 'Stirring',\n",
       " 'Storeing',\n",
       " 'Storing',\n",
       " 'Taking',\n",
       " 'Tempting',\n",
       " 'Threatening',\n",
       " 'Transporting',\n",
       " 'Trimming',\n",
       " 'Turning',\n",
       " 'Unraveling',\n",
       " 'Waking',\n",
       " 'Working'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any mispellings with the affordances created\n",
    "affs = set(aff_df['aff_class'].to_list())\n",
    "affs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_col(text):\n",
    "    \"\"\"\n",
    "    For the action affordances determined, filter out specific words that resulted with typos.\n",
    "    \"\"\"            \n",
    "    edit_out = ['Storeing', 'Stiring', 'Runing', 'Pareing', 'Serveding', 'Leaveing', 'Makeing', 'Cuting', 'Leaveing', 'Storeing']\n",
    "    edit_in = ['Storing', 'Stirring', 'Running', 'Paring', 'Serving', 'Leaving', 'Making', 'Cutting', 'Leaving', 'Storing']\n",
    "    \n",
    "    if text in edit_out:\n",
    "        index = edit_out.index(text)\n",
    "        new_text = edit_in[index]\n",
    "        return new_text\n",
    "    else:\n",
    "        return text\n",
    "        \n",
    "# apply the function to the df\n",
    "aff_df['aff_class'] = aff_df['aff_class'].apply(filter_col)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the desired triples for the graph\n",
    "\n",
    "# < affordance subclass, rdfs:subClassOf, aff:Affordance >\n",
    "action_affs = aff_df.aff_class.to_list()\n",
    "action_affs_set = set(action_affs)\n",
    "action_affs_set.remove(None)\n",
    "for aff in action_affs_set:\n",
    "    merged_g.add( (aff_ns[URIRef(aff)], RDFS.subClassOf, aff_ns.Affordance) )\n",
    "\n",
    "for index, row in aff_df.iterrows():\n",
    "    # < UsedFor object, a, aff:Action >\n",
    "    merged_g.add( (cnc_ns['en/' + row['usage_o']], RDF.type, aff_ns.Action) )\n",
    "    merged_g.add( (cnc_ns[row['entities']], aff_ns.potential_action, cnc_ns['en/' + row['usage_o']]) )\n",
    "    # < UsedFor object, a, Affordance Subclass >\n",
    "    if row['aff_class'] == None:\n",
    "        continue\n",
    "    else:\n",
    "        merged_g.add( (cnc_ns['en/' + row['usage_o']], aff_ns.action_affordance, aff_ns[row['aff_class']]) )\n",
    "        merged_g.add( (cnc_ns[row['entities']], aff_ns.affords, aff_ns[row['aff_class']]) )\n",
    "#         print((cnc_ns[row['entities']], aff_ns.affords, aff_ns[row['aff_class']]))\n",
    "#         print(aff_ns[row['aff_class']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(aff_df.aff_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2620"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:ReceivesAction_ --> removing these triples because other relations give similar information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in merged_g.triples( (None, cnr_ns.ReceivesAction, None) ):\n",
    "    merged_g.remove( (cnc_ns[s[27:]], cnr_ns.ReceivesAction, cnc_ns[o[27:]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:MadeOf_ --> only keep triples in which the subject of the triple is an instance of the BFT onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = ['milk', 'apple', 'lemon', 'refrigerator', 'coffee', 'croissant', 'garnish', 'hardboiled_egg', 'scrambled_egg', 'fried_egg', 'orange_juice', 'apple_juice', 'butter', 'salt_shaker', 'pepper_shaker', 'bread_basket', 'egg_cup', 'milk_pitcher', 'fork', 'knife', 'spoon', 'butter_knife', 'glass', 'teacup', 'sauce_dish', 'butter_dish', 'bread_plate', 'teacup_plate', 'dining_table', 'dining_chair', 'cupboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in merged_g.triples( (None, cnr_ns.MadeOf, None) ):\n",
    "    if s[30:] not in instances:\n",
    "        merged_g.remove( (cnc_ns[s[27:]], cnr_ns.MadeOf, cnc_ns[o[27:]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:PartOf_ --> remove triples about glass because they are not very relevant to the kitchen domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in merged_g.triples( (None, cnr_ns.PartOf, None) ):\n",
    "    if \"glass\" in s[30:]:\n",
    "        merged_g.remove( (cnc_ns[s[27:]], cnr_ns.PartOf, cnc_ns[o[27:]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation: _cnr:HasPrequisite_ --> allocate 'A' in cnr:HasPrerequisite to a instance of aff:Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_classes = set()\n",
    "actions = []\n",
    "for s,p,o in merged_g.triples( (None, cnr_ns.HasPrerequisite, None) ):\n",
    "    action_verb = s[30:].split('_')\n",
    "    action_aff = action_verb[0]\n",
    "    action_aff_uri = URIRef(action_aff.capitalize())\n",
    "#     print(action_aff)\n",
    "    merged_g.add( (cnc_ns[s[27:]], RDF.type, aff_ns.Action) )\n",
    "#     print((cnc_ns[s[27:]], RDF.type, aff_ns.Action))\n",
    "    merged_g.add( (aff_ns[action_aff_uri], RDFS.subClassOf, aff_ns.Affordance) )\n",
    "    merged_g.add( (cnc_ns[s[27:]], RDF.type, aff_ns[action_aff_uri]) )\n",
    "    merged_g.add( (cnc_ns[o[27:]], aff_ns.potential_action, cnc_ns[s[27:]]) )\n",
    "#     print((cnc_ns[o[27:]], aff_ns.potential_action, cnc_ns[s[27:]]))\n",
    "#     print(s[27:])\n",
    "    \n",
    "#     print((cnc_ns[s[27:]], RDF.type, aff_ns[action_aff_uri]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2585"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking CN Concepts with BFT ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct_s = cn_g.query(\n",
    "# \"\"\"\n",
    "# prefix cn: <http://api.conceptnet.io/> \n",
    "# prefix cnc: <http://api.conceptnet.io/c/> \n",
    "# prefix cnr: <http://api.conceptnet.io/r/> \n",
    "# prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "# prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "# prefix wi: <http://purl.org/ontology/wi/core#> \n",
    "# prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "# prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "# SELECT distinct ?s WHERE { \n",
    "#   ?s a rdfs:Resource. \n",
    "#   ?assertion rdf:subject ?s;\n",
    "#              rdf:predicate ?p.\n",
    "#   FILTER(! (?p = cnr:ExternalURL) )\n",
    "# }\n",
    "# \"\"\")\n",
    "# len(distinct_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_s = cn_g.query(\n",
    "\"\"\"\n",
    "prefix cn: <http://api.conceptnet.io/> \n",
    "prefix cnc: <http://api.conceptnet.io/c/> \n",
    "prefix cnr: <http://api.conceptnet.io/r/> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix wi: <http://purl.org/ontology/wi/core#> \n",
    "prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "SELECT distinct ?s WHERE { \n",
    "  ?s ?p ?o.\n",
    "  FILTER(! (?p = cnr:ExternalURL) )\n",
    "}\n",
    "\"\"\")\n",
    "len(distinct_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_o = cn_g.query(\n",
    "\"\"\"\n",
    "prefix cnr: <http://api.conceptnet.io/r/> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix wi: <http://purl.org/ontology/wi/core#> \n",
    "prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "SELECT distinct ?o WHERE { \n",
    "  ?s ?p ?o.\n",
    "  FILTER(! (?p = cnr:ExternalURL) )\n",
    "}\n",
    "\"\"\")\n",
    "len(distinct_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance to compare strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein\n",
    "# import the enchant module \n",
    "import enchant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# subject case\n",
    "c=0\n",
    "with open('test_s.txt', 'w') as file:\n",
    "    for i in instances:\n",
    "        str1 = i\n",
    "        for r in distinct_s:\n",
    "            str2 = r.s[30:]\n",
    "#             print(str1, str2)\n",
    "            dist = enchant.utils.levenshtein(str1, str2)\n",
    "            ratio = ((len(str1)+len(str2)) - dist) / (len(str1)+len(str2))\n",
    "            if ratio > 0.83:\n",
    "                c +=1\n",
    "                file.write(f'{str(ratio)} -- {i} -- {r.s[30:]}\\n')\n",
    "#                 print(cnc_ns[r.s[32:]])\n",
    "                merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), OWL.sameAs, cnc_ns[r.s[27:]]))\n",
    "#                 print(cnc_ns[r.s[27:]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# object case\n",
    "c1=0\n",
    "with open('test_o.txt', 'w') as file:\n",
    "    for i in instances:\n",
    "        str1 = i\n",
    "        for r in distinct_o:\n",
    "#             print(str1, str2)\n",
    "            str2 = r.o[30:]\n",
    "            dist = enchant.utils.levenshtein(str1, str2)\n",
    "            ratio = ((len(str1)+len(str2)) - dist) / (len(str1)+len(str2))\n",
    "            if ratio > 0.83:\n",
    "                c1 += 1\n",
    "                file.write(f'{str(ratio)} -- {i} -- {r.o[30:]}\\n')\n",
    "                merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), OWL.sameAs, cnc_ns[r.o[27:]]))\n",
    "#                 print(cnc_ns[r.o[27:]])\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# exact match of string matching (comparing how this works against the Levenshtein method)\n",
    "cnt = 0\n",
    "for i in instances:\n",
    "    for r in distinct_s:\n",
    "#         print(i, r.s[30:])\n",
    "        if i == str(r.s[30:]):\n",
    "            cnt +=1\n",
    "    for r in distinct_o:\n",
    "#         print(i, r.o)\n",
    "        if i == str(r.o[30:]):\n",
    "            cnt +=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that more links are created through the Levenshtein algorithm compared to the exact string match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2632"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that 67 triples are added to the graph after linking CN graph to base graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create closeMatch links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links instances following that the instance string is in the response string\n",
    "# eg. if instance is 'croissant' and the repsonse is 'butter_croissant', it would be a match\n",
    "\n",
    "same_as_objects = []\n",
    "for s,p,o in merged_g.triples( (None, OWL.sameAs, None) ):\n",
    "#     print(s,p,o)\n",
    "    same_as_objects.append(o[30:])\n",
    "#     print(o[30:])\n",
    "\n",
    "with open('test_contains.txt', 'w') as file:  # Use file to refer to the file object\n",
    "    for i in instances:\n",
    "        for r in distinct_s:\n",
    "#             print(r.s[30:])\n",
    "            s_concept = str(r.s[30:])\n",
    "            if i in s_concept:\n",
    "                if s_concept in same_as_objects:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{i} ------- {str(r.s)}\\n')\n",
    "                    merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), skos_ns.closeMatch, cnc_ns[r.s[30:]]) ) \n",
    "        for r in distinct_o:\n",
    "            o_concept = str(r.o[30:])\n",
    "            if i in o_concept:\n",
    "                if o_concept in same_as_objects:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{i} ------- {str(r.o)}\\n')\n",
    "                    merged_g.add( (URIRef(f'http://test.org/bft.owl#{i}'), skos_ns.closeMatch, cnc_ns[r.o[30:]]) )\n",
    "    \n",
    "# if the triple exists with that subject, then continue because there is an owlsameas triple of the instnace, else make the triple with skos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "affords_q = merged_g.query(\n",
    "\"\"\"\n",
    "prefix aff: <http://test.org/affordance.owl#>\n",
    "prefix cn: <http://api.conceptnet.io/> \n",
    "prefix cnc: <http://api.conceptnet.io/c/> \n",
    "prefix cnr: <http://api.conceptnet.io/r/> \n",
    "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "prefix xml: <http://www.w3.org/XML/1998/namespace> \n",
    "prefix xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "select ?ke ?aff where\n",
    "{\n",
    "  ?ke aff:potential_action ?action.\n",
    "  ?action a ?aff.\n",
    "  ?aff rdfs:subClassOf aff:Affordance.}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in affords_q:\n",
    "#     print(URIRef(cnc_ns[row.ke[27:]]), URIRef(aff_ns[row.aff[31:]]))\n",
    "    merged_g.add( (URIRef(cnc_ns[row.ke[27:]]), aff_ns.affords, URIRef(aff_ns[row.aff[31:]])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize and save new merged graph with CN entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first remove noisy triples\n",
    "merged_g.remove( (URIRef('http://test.org/bft.owl#fork'), OWL.sameAs, URIRef('http://api.conceptnet.io/c/en/pork')) )\n",
    "merged_g.remove( (URIRef('http://test.org/bft.owl#fork'), OWL.sameAs, URIRef('http://api.conceptnet.io/c/en/work')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_g.serialize('aff_bft_cn_Final.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2865"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
